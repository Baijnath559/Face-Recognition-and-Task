{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK-6 FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the required library ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib as s\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import os\n",
    "from email.message import EmailMessage\n",
    "import pywhatkit\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading haar face classifier  ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter no. of user: 2\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter no. of user: \"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating n number of users ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = [i+1 for i in range(0,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking input of user names ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter user 1 name : Baijnath\n",
      "Enter user 2 name : Mukul\n"
     ]
    }
   ],
   "source": [
    "USER_NAME = []     \n",
    "\n",
    "for i in range(0,n):\n",
    "    name = input(\"Enter user \" + str(i+1) + \" name : \")\n",
    "    USER_NAME.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function that detects faces and return the cropped face. If no face detected, it will return the input img. ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-7-44805affd518>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def face_extractor(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3,5)\n",
    "    \n",
    "    if faces is (): \n",
    "        return None\n",
    "    \n",
    "    #crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        \n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function which will create folder for both users ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dir (i):\n",
    "    os.chdir(\"E:/Linux world/Task/Task6/Faces\")\n",
    "    os.system(\"mkdir \"+ str(USER_NAME[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function which will initialize webcam and collect 100 samples of img from webcam ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(i):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "    \n",
    "        ret, photo = cap.read()\n",
    "        if face_extractor(photo) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(photo),(200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)  #training would be faster for B/W img\n",
    "        \n",
    "        #save file in specified directory with unique name\n",
    "            change_dir(i)\n",
    "            file_name_path = 'E:/Linux world/Task/Task6/Faces/'+ str(USER_NAME[i]) +\"/\"+ str(count) + '.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        #put count on img and display live count\n",
    "            cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255),2)\n",
    "            cv2.imshow('Face cropper', face)\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        if cv2.waitKey(1) == 13 or count == 100:  #13 is for ENTER key\n",
    "            break\n",
    "        \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Sample Collection for \"+ str(USER_NAME[i]) +\" completed\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample collection from both user ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Collection for Baijnath completed\n",
      "Sample Collection for Mukul completed\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n):\n",
    "    capture(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will help to get the training data and then it will train both models ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBPH_obj = [None, None]\n",
    "\n",
    "\n",
    "def train_model(j):\n",
    "    data_path = 'E:/Linux world/Task/Task6/Faces/'+ str(USER_NAME[j]) + \"/\"     #. is used for current dir\n",
    "    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "\n",
    "    #create arrays for training data and labels\n",
    "    Train_data , Labels = [], []\n",
    "\n",
    "    #open training images in our datapath\n",
    "    #create numpy array for training data\n",
    "\n",
    "    for i , files in enumerate(onlyfiles):\n",
    "        image_path = data_path + onlyfiles[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        Train_data.append(np.asarray(images, dtype = np.uint8))\n",
    "        Labels.append(i)\n",
    "\n",
    "\n",
    "    #create a numpy array for both training data and lebels\n",
    "    Labels = np.asarray(Labels, dtype = np.int32)\n",
    "\n",
    "    \n",
    "    #initialize facial recognizer\n",
    "    #model = cv2.face.createLBPHFaceRecognizer()\n",
    "    # Note : for opencv 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "    #pip install opencv-contrib-python\n",
    "    #model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "    LBPH_obj[j] = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "    #train the model\n",
    "    LBPH_obj[j].train(np.asarray(Train_data), np.asarray(Labels))\n",
    "    print(\"Model for \" +str(USER_NAME[j])+ \" trained successfully\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling function to train the models ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Baijnath trained successfully\n",
      "Model for Mukul trained successfully\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,n):\n",
    "    train_model(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will help to get the region of interest. ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-13-83000bab0f05>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is():\n"
     ]
    }
   ],
   "source": [
    "def face_detector(img, size = 0.5):\n",
    "    \n",
    "    #convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w, y+h),(0,255,0),2)\n",
    "        region_of_interest = img[y:y+h, x:x+w]\n",
    "        region_of_interest = cv2.resize(region_of_interest, (200,200))\n",
    "        \n",
    "    return img, region_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for sending email ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email():\n",
    "    send_email = \"baijnath.k03022000@gmail.com\"\n",
    "\n",
    "    with open(\"E:/Linux world/Task/Task6/password.txt\") as file:                       #reading password\n",
    "        pswrd = file.read()\n",
    "\n",
    "    msg = EmailMessage()\n",
    "\n",
    "    msg[\"Subject\"] = 'Face recognition'\n",
    "    msg['From'] = send_email\n",
    "    msg['To'] = 'baijnath.k3022000@gmail.com'\n",
    "\n",
    "    msg.set_content(\"This is face of Baijnath\")\n",
    "\n",
    "    server = s.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "    server.login(send_email,pswrd)\n",
    "    print(\"Login Success!!\")\n",
    "\n",
    "\n",
    "    server.send_message(msg)\n",
    "    print(\"Email has been sent successfully\")\n",
    "\n",
    "    server.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for sending whatsapp msg ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatsapp():\n",
    "    \n",
    "    file = open(\"E:/Linux world/Task/Task6/phone.txt\")                     \n",
    "    ph_no = file.read()\n",
    "    pywhatkit.sendwhatmsg_instantly(ph_no, \"This msg was sent using python code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will create a new EC2 instance and EBS volume and then attach both ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_vol():\n",
    "    i_id = subprocess.getoutput(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --instance-type t2.micro --count 1 --subnet-id subnet-ef8d6784 --security-group-ids sg-0d36a0a2d9eb574ea --key-name awskeypair --query Instances[*].[InstanceId] --output text\")\n",
    "    print(\"EC2 Instance with instance id : {} created successfully\".format(i_id))\n",
    "    v_id = subprocess.getoutput(\"aws ec2 create-volume --volume-type gp2 --size 5 --availability-zone ap-south-1a --query VolumeId --output text\")\n",
    "    print(\"Created 5GB EBS Volume with volume id : {} created\".format(v_id))\n",
    "    attach()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach():\n",
    "    vid = input(\"Enter volume id: \")\n",
    "    iid = input(\"Enter instance id: \")\n",
    "    subprocess.getoutput(\"aws ec2 attach-volume --volume-id \" + vid +  \" --instance-id \" + iid + \" --dev /dev/sdf\")\n",
    "    print(\"EBS volume Attached successfully to the newly created instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face recognition part ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "def capture():\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        ret, photo = cap.read()\n",
    "        image, face = face_detector(photo)\n",
    "    \n",
    "        try:\n",
    "            k = 0\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            #pass face to prediction model\n",
    "            #\"result\" will be a tuple contaning the label and the confidence value\n",
    "            results = LBPH_obj[k].predict(face)\n",
    "            \n",
    "         \n",
    "            if results[1] < 500:                        #results[1] ==> confidence value\n",
    "                confidence = int(100*(1 - (results[1])/400))\n",
    "                \n",
    "            if confidence > 88:\n",
    "                count_1 += 1\n",
    "                display_string = str(confidence) + ' % Confident he is Baijnath'\n",
    "                cv2.putText(image, display_string, (100,120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "                cv2.putText(image, \"Email & whatsapp msg done\", (100,400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow(\"Face Recognition\", image)\n",
    "                if count_1 == 10:\n",
    "                    email()\n",
    "                    whatsapp()\n",
    "                    \n",
    "                  \n",
    "\n",
    "            k += 1                                 #switching to 2nd model\n",
    "            display_string= \"\"\n",
    "            results = LBPH_obj[k].predict(face)\n",
    "                \n",
    "            if results[1] < 500:\n",
    "                confidence = int(100*(1 - (results[1])/400))            \n",
    "        \n",
    "            if confidence > 88:\n",
    "                count_2 += 1\n",
    "                txt =\"Instance launched\"\n",
    "                display_string = str(confidence) + ' % Confident he is Mukul'\n",
    "                cv2.putText(image, display_string, (80,100), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "                cv2.putText(image, txt, (100,400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                \n",
    "                if count_2 == 10:\n",
    "                    instance_vol()\n",
    "                    \n",
    "                cv2.imshow(\"Face Recognition\", image)\n",
    "                \n",
    "        except:\n",
    "            cv2.imshow(\"Face Recognition\", image)\n",
    "            pass\n",
    "        \n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Success!!\n",
      "Email has been sent successfully\n",
      "EC2 Instance with instance id : i-024b262ad75ec10ab created successfully\n",
      "Created 5GB EBS Volume with volume id : vol-0a5545ef2eb31813c created\n",
      "Enter volume id: vol-0a5545ef2eb31813c\n",
      "Enter instance id: i-024b262ad75ec10ab\n",
      "EBS volume Attached successfully to the newly created instance\n"
     ]
    }
   ],
   "source": [
    "capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THANK YOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = os.system(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "d = subprocess.getoutput(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(\"aws ec2 attach-volume --volume-id vol-01cf49290c314f004 --instance-id i-088b2e9d54625868e --dev /dev/sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "def capture():\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        ret, photo = cap.read()\n",
    "        image, face = face_detector(photo)\n",
    "    \n",
    "        try:\n",
    "            k = 0\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            #pass face to prediction model\n",
    "            #\"result\" will be a tuple contaning the label and the confidence value\n",
    "            results = LBPH_obj[k].predict(face)\n",
    "            \n",
    "         \n",
    "            if results[1] < 500:                        #results[1] ==> confidence value\n",
    "                confidence = int(100*(1 - (results[1])/400))\n",
    "                \n",
    "            if confidence > 88:\n",
    "                count_1 += 1\n",
    "                display_string = str(confidence) + ' % Confident he is Baijnath'\n",
    "                cv2.putText(image, display_string, (100,120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "                cv2.putText(image, \"Email & whatsapp msg done\", (100,400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow(\"Face Recognition\", image)\n",
    "                if count_1 == 1:\n",
    "                    send_email()\n",
    "                    whatsapp_msg()\n",
    "                \n",
    "                \n",
    "\n",
    "            k += 1                                 #switching to 2nd model\n",
    "            display_string= \"\"\n",
    "            results = LBPH_obj[k].predict(face)\n",
    "                \n",
    "            if results[1] < 500:\n",
    "                confidence = int(100*(1 - (results[1])/400))            \n",
    "        \n",
    "            if confidence > 88:\n",
    "                count_2 += 1\n",
    "                txt =\"Instance launched\"\n",
    "                display_string = str(confidence) + ' % Confident he is Mukul'\n",
    "                cv2.putText(image, display_string, (80,100), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "                cv2.putText(image, txt, (100,400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                if count_2 == 1:\n",
    "                    instance()\n",
    "                    volume()\n",
    "                cv2.imshow(\"Face Recognition\", image)\n",
    "                \n",
    "        except:\n",
    "            cv2.imshow(\"Face Recognition\", image)\n",
    "            pass\n",
    "        \n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
